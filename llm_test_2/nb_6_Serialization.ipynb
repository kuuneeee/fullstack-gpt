{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. openAI의 모델을 사용할 때 우리가 지출하는 비용을 아는 방법\n",
    "# 한번 call할때마다 얼마나 돈을 지출하고 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 138\n",
      "\tPrompt Tokens: 14\n",
      "\tCompletion Tokens: 124\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    # with get_openai_callback() as usage: 으로 코드를 감싸서\n",
    "    # 이 안에 모델을 호출하고\n",
    "    chat.predict(\"What is the recipe for soju\")\n",
    "    print(usage)\n",
    "    # print(usage)를 호출하면\n",
    "    # 호출한 것들에 대한 총 비용이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients:\n",
      "- 1 bottle of soju\n",
      "- 1-2 cups of water\n",
      "- 1-2 tablespoons of sugar (optional)\n",
      "- Ice cubes\n",
      "\n",
      "Instructions:\n",
      "1. Chill the bottle of soju in the refrigerator for at least a few hours before serving.\n",
      "2. In a small pitcher, mix the soju with water. The ratio of soju to water can vary depending on your preference, but a common ratio is 1:1 or 1:2.\n",
      "3. If you prefer a sweeter taste, you can add sugar to the soju and water mixture and stir until the sugar is dissolved.\n",
      "4. Fill glasses with ice cubes and pour the soju mixture over the ice.\n",
      "5. Serve immediately and enjoy! Ingredients:\n",
      "- 4 cups all-purpose flour\n",
      "- 1 packet (2 1/4 tsp) active dry yeast\n",
      "- 1 1/2 cups warm water\n",
      "- 2 tbsp sugar\n",
      "- 2 tbsp olive oil\n",
      "- 1 1/2 tsp salt\n",
      "\n",
      "Instructions:\n",
      "1. In a large bowl, dissolve the yeast and sugar in the warm water. Let it sit for about 5 minutes until it becomes frothy.\n",
      "2. Add the olive oil and salt to the yeast mixture and stir to combine.\n",
      "3. Gradually add the flour to the mixture, stirring until a dough forms.\n",
      "4. Turn the dough out onto a floured surface and knead for about 10 minutes, until the dough is smooth and elastic.\n",
      "5. Place the dough in a greased bowl, cover with a clean kitchen towel, and let it rise in a warm place for about 1 hour, or until it has doubled in size.\n",
      "6. Preheat the oven to 375°F (190°C).\n",
      "7. Punch down the dough and shape it into a loaf. Place the loaf on a greased baking sheet and let it rise for another 30 minutes.\n",
      "8. Bake the bread for 30-35 minutes, or until it is golden brown and sounds hollow when tapped on the bottom.\n",
      "9. Let the bread cool on a wire rack before slicing and serving. Enjoy! \n",
      "\n",
      "Cost : 0.00000\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    # with get_openai_callback() as usage: 으로 코드를 감싸서\n",
    "    # 이 안에 모델을 호출하고\n",
    "    a = chat.predict(\"What is the recipe for soju\")\n",
    "    b = chat.predict(\"What is the recipe for bread\")\n",
    "\n",
    "    print(a, b, \"\\n\")\n",
    "    print(f\"Cost : {float(usage.total_cost):0.5f}\")\n",
    "    # print(usage)를 호출하면\n",
    "    # 호출한 것들에 대한 총 비용이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델을 어떻게 저장하고 불러오는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain\\llms\\openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "d:\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain\\llms\\openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# llms = OpenAI(\n",
    "#     model_name=\"gpt-3.5-turbo-16k\",\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=450,\n",
    "# )\n",
    "\n",
    "# # 모델 저장\n",
    "# llms.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Loading openai-chat LLM not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m load_model\n",
      "File \u001b[1;32md:\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain\\llms\\loading.py:44\u001b[0m, in \u001b[0;36mload_llm\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile type must be json or yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Load the LLM from the config now.\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_llm_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\FULLSTACK-GPT\\env\\Lib\\site-packages\\langchain\\llms\\loading.py:21\u001b[0m, in \u001b[0;36mload_llm_from_config\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     18\u001b[0m type_to_cls_dict \u001b[38;5;241m=\u001b[39m get_type_to_cls_dict()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m type_to_cls_dict:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m LLM not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m llm_cls \u001b[38;5;241m=\u001b[39m type_to_cls_dict[config_type]()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llm_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "\u001b[1;31mValueError\u001b[0m: Loading openai-chat LLM not supported"
     ]
    }
   ],
   "source": [
    "load_model = load_llm(\"model.json\")\n",
    "load_model\n",
    "\n",
    "# 지금은 업데이트되서 사용할 수 없는거처럼 보임\n",
    "# 일단 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
