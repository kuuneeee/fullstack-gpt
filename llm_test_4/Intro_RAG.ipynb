{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation : 검색 증강 생성\n",
    "\n",
    "모델은 많은 데이터를 통해 학습되지만, 때로는 개인적인 데이터들에는 접근할 수 없음 -> 개인 DB나 문서 등\n",
    "        \n",
    "=> 그래서 RAG 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 무슨 말이냐?\n",
    "\n",
    "예를 들어, A라는 것에 대해 질문했을때 2가지 단계를 거치게 됨\n",
    "\n",
    "이때, 모델은 A에 대해 전혀 학습되어 있지 않다고 가정\n",
    "\n",
    "\n",
    "#### 1. 질문과 문서를 Prompt로 구성\n",
    "\n",
    "- 질문 문자열과 그 질문의 단어(토큰)을 \"포함\"한, 그 단어와 관련이 있는 문서를 찾음\n",
    "\n",
    "- 이때 \"포함\"은 정확하게 그 단어가 있는 걸 말하는 게 아님. Vector Space 서칭이나, 의미론적 검색 등을 통해 단어를 \"포함\"하는 문서를 찾음\n",
    "\n",
    "#### 2. Prompt로 만들어지면, LLM에 전달\n",
    "\n",
    "- 모델은 기존에 학습된 수 많은 데이터와 함께, 전달된 Prompt를 고려하여 답변을 하게 됨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 즉, 개인으로부터 제공된 데이터를 사용하거나 탐색함으로써 LM의 능력을 확장하는 것이 목적\n",
    "\n",
    "- 필요에 따라 기존의 학습된 데이터를 참고하지 않고, 추가적으로 제공된 데이터만을 사용해서 답변하게 할 수도 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
